{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WlirWI9o6_tD"
      },
      "outputs": [],
      "source": [
        "faqs=\"\"\"Human being, a culture-bearing primate classified in the genus Homo, especially the species H sapiens.\n",
        "Human beings are anatomically similar and related to the great apes but are distinguished by a more highly developed brain and a resultant\n",
        "capacity for articulate speech and abstract reasoning. In addition, human beings display a marked erectness of body carriage that frees\n",
        "the hands for use as manipulative members. Some of these characteristics, however, are not entirely unique to humans. The gap in cognition,\n",
        "as in anatomy, between humans and the great apes (orangutans, gorillas, chimpanzees, and bonobos) is much less than was once thought,\n",
        "as they have been shown to possess a variety of advanced cognitive abilities formerly believed to be restricted to humans.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "lWmW6Ot5FpOK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "XQogaF-kKT0a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "BxZdq-AELZ53"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_-VMSYaLgAl",
        "outputId": "20634d36-6def-43c4-fcc1-87f8e8f6585a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'and': 3,\n",
              " 'to': 4,\n",
              " 'in': 5,\n",
              " 'human': 6,\n",
              " 'are': 7,\n",
              " 'of': 8,\n",
              " 'as': 9,\n",
              " 'humans': 10,\n",
              " 'beings': 11,\n",
              " 'great': 12,\n",
              " 'apes': 13,\n",
              " 'for': 14,\n",
              " 'being': 15,\n",
              " 'culture': 16,\n",
              " 'bearing': 17,\n",
              " 'primate': 18,\n",
              " 'classified': 19,\n",
              " 'genus': 20,\n",
              " 'homo': 21,\n",
              " 'especially': 22,\n",
              " 'species': 23,\n",
              " 'h': 24,\n",
              " 'sapiens': 25,\n",
              " 'anatomically': 26,\n",
              " 'similar': 27,\n",
              " 'related': 28,\n",
              " 'but': 29,\n",
              " 'distinguished': 30,\n",
              " 'by': 31,\n",
              " 'more': 32,\n",
              " 'highly': 33,\n",
              " 'developed': 34,\n",
              " 'brain': 35,\n",
              " 'resultant': 36,\n",
              " 'capacity': 37,\n",
              " 'articulate': 38,\n",
              " 'speech': 39,\n",
              " 'abstract': 40,\n",
              " 'reasoning': 41,\n",
              " 'addition': 42,\n",
              " 'display': 43,\n",
              " 'marked': 44,\n",
              " 'erectness': 45,\n",
              " 'body': 46,\n",
              " 'carriage': 47,\n",
              " 'that': 48,\n",
              " 'frees': 49,\n",
              " 'hands': 50,\n",
              " 'use': 51,\n",
              " 'manipulative': 52,\n",
              " 'members': 53,\n",
              " 'some': 54,\n",
              " 'these': 55,\n",
              " 'characteristics': 56,\n",
              " 'however': 57,\n",
              " 'not': 58,\n",
              " 'entirely': 59,\n",
              " 'unique': 60,\n",
              " 'gap': 61,\n",
              " 'cognition': 62,\n",
              " 'anatomy': 63,\n",
              " 'between': 64,\n",
              " 'orangutans': 65,\n",
              " 'gorillas': 66,\n",
              " 'chimpanzees': 67,\n",
              " 'bonobos': 68,\n",
              " 'is': 69,\n",
              " 'much': 70,\n",
              " 'less': 71,\n",
              " 'than': 72,\n",
              " 'was': 73,\n",
              " 'once': 74,\n",
              " 'thought': 75,\n",
              " 'they': 76,\n",
              " 'have': 77,\n",
              " 'been': 78,\n",
              " 'shown': 79,\n",
              " 'possess': 80,\n",
              " 'variety': 81,\n",
              " 'advanced': 82,\n",
              " 'cognitive': 83,\n",
              " 'abilities': 84,\n",
              " 'formerly': 85,\n",
              " 'believed': 86,\n",
              " 'be': 87,\n",
              " 'restricted': 88}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in faqs.split('.'):\n",
        "  for portion in sentence.split(','):\n",
        "    print(portion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38-oI_JLLnAG",
        "outputId": "d669cb27-81ac-43a4-d28a-5293fbd58f32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human being\n",
            " a culture-bearing primate classified in the genus Homo\n",
            " especially the species H sapiens\n",
            "\n",
            "Human beings are anatomically similar and related to the great apes but are distinguished by a more highly developed brain and a resultant\n",
            "capacity for articulate speech and abstract reasoning\n",
            " In addition\n",
            " human beings display a marked erectness of body carriage that frees\n",
            "the hands for use as manipulative members\n",
            " Some of these characteristics\n",
            " however\n",
            " are not entirely unique to humans\n",
            " The gap in cognition\n",
            "\n",
            "as in anatomy\n",
            " between humans and the great apes (orangutans\n",
            " gorillas\n",
            " chimpanzees\n",
            " and bonobos) is much less than was once thought\n",
            "\n",
            "as they have been shown to possess a variety of advanced cognitive abilities formerly believed to be restricted to humans\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = []\n",
        "for sentence in faqs.split('.'):\n",
        "  for portion in sentence.split(','):\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([portion])[0]\n",
        "\n",
        "    for i in range(1,len(tokenized_sentence)):\n",
        "      input_seq.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "kwtVSdJpNX9k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSUV52YnO7ED",
        "outputId": "27dc17c6-4193-4243-f6ec-5da810ab85fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 15],\n",
              " [2, 16],\n",
              " [2, 16, 17],\n",
              " [2, 16, 17, 18],\n",
              " [2, 16, 17, 18, 19],\n",
              " [2, 16, 17, 18, 19, 5],\n",
              " [2, 16, 17, 18, 19, 5, 1],\n",
              " [2, 16, 17, 18, 19, 5, 1, 20],\n",
              " [2, 16, 17, 18, 19, 5, 1, 20, 21],\n",
              " [22, 1],\n",
              " [22, 1, 23],\n",
              " [22, 1, 23, 24],\n",
              " [22, 1, 23, 24, 25],\n",
              " [6, 11],\n",
              " [6, 11, 7],\n",
              " [6, 11, 7, 26],\n",
              " [6, 11, 7, 26, 27],\n",
              " [6, 11, 7, 26, 27, 3],\n",
              " [6, 11, 7, 26, 27, 3, 28],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31, 2],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31, 2, 32],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31, 2, 32, 33],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31, 2, 32, 33, 34],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31, 2, 32, 33, 34, 35],\n",
              " [6, 11, 7, 26, 27, 3, 28, 4, 1, 12, 13, 29, 7, 30, 31, 2, 32, 33, 34, 35, 3],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37,\n",
              "  14],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37,\n",
              "  14,\n",
              "  38],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37,\n",
              "  14,\n",
              "  38,\n",
              "  39],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37,\n",
              "  14,\n",
              "  38,\n",
              "  39,\n",
              "  3],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37,\n",
              "  14,\n",
              "  38,\n",
              "  39,\n",
              "  3,\n",
              "  40],\n",
              " [6,\n",
              "  11,\n",
              "  7,\n",
              "  26,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  4,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  29,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  2,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  3,\n",
              "  2,\n",
              "  36,\n",
              "  37,\n",
              "  14,\n",
              "  38,\n",
              "  39,\n",
              "  3,\n",
              "  40,\n",
              "  41],\n",
              " [5, 42],\n",
              " [6, 11],\n",
              " [6, 11, 43],\n",
              " [6, 11, 43, 2],\n",
              " [6, 11, 43, 2, 44],\n",
              " [6, 11, 43, 2, 44, 45],\n",
              " [6, 11, 43, 2, 44, 45, 8],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1, 50],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1, 50, 14],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1, 50, 14, 51],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1, 50, 14, 51, 9],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1, 50, 14, 51, 9, 52],\n",
              " [6, 11, 43, 2, 44, 45, 8, 46, 47, 48, 49, 1, 50, 14, 51, 9, 52, 53],\n",
              " [54, 8],\n",
              " [54, 8, 55],\n",
              " [54, 8, 55, 56],\n",
              " [7, 58],\n",
              " [7, 58, 59],\n",
              " [7, 58, 59, 60],\n",
              " [7, 58, 59, 60, 4],\n",
              " [7, 58, 59, 60, 4, 10],\n",
              " [1, 61],\n",
              " [1, 61, 5],\n",
              " [1, 61, 5, 62],\n",
              " [9, 5],\n",
              " [9, 5, 63],\n",
              " [64, 10],\n",
              " [64, 10, 3],\n",
              " [64, 10, 3, 1],\n",
              " [64, 10, 3, 1, 12],\n",
              " [64, 10, 3, 1, 12, 13],\n",
              " [64, 10, 3, 1, 12, 13, 65],\n",
              " [3, 68],\n",
              " [3, 68, 69],\n",
              " [3, 68, 69, 70],\n",
              " [3, 68, 69, 70, 71],\n",
              " [3, 68, 69, 70, 71, 72],\n",
              " [3, 68, 69, 70, 71, 72, 73],\n",
              " [3, 68, 69, 70, 71, 72, 73, 74],\n",
              " [3, 68, 69, 70, 71, 72, 73, 74, 75],\n",
              " [9, 76],\n",
              " [9, 76, 77],\n",
              " [9, 76, 77, 78],\n",
              " [9, 76, 77, 78, 79],\n",
              " [9, 76, 77, 78, 79, 4],\n",
              " [9, 76, 77, 78, 79, 4, 80],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85, 86],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85, 86, 4],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85, 86, 4, 87],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85, 86, 4, 87, 88],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85, 86, 4, 87, 88, 4],\n",
              " [9, 76, 77, 78, 79, 4, 80, 2, 81, 8, 82, 83, 84, 85, 86, 4, 87, 88, 4, 10]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to apply zero padding to make size same for all input and ouput\n",
        "max_len = max([len(x) for x in input_seq])"
      ],
      "metadata": {
        "id": "VsPy7R2jPDvQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSkmKdKaZTiz",
        "outputId": "d079c979-db94-473c-b074-65ed0eb78ae1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_seq = pad_sequences(input_seq,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "cB4-i4etPn5e"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dy48TZrQb-M",
        "outputId": "cd80dc2d-97c3-4e7b-9697-f13b7dc45c1c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_input_seq[:,:-1]"
      ],
      "metadata": {
        "id": "i4-P_9DXPfsO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_seq[:,-1]"
      ],
      "metadata": {
        "id": "4NcDaQs0QR_u"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There is possibility that this is regression or muliclass classification problem\n",
        "# If we consider it as regression problem than we might get value 2.1 but no word is associated with this number\n",
        "# Hence we will use multi-class-classification and we will use one-hot-encoding"
      ],
      "metadata": {
        "id": "qbMGeOWsQ2ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNKQg-BVR2Yz",
        "outputId": "eb6cc9c0-5c06-4ba7-bcc4-7f0d7e7bab09"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRRbtqQgR4L0",
        "outputId": "31490d69-1b0a-4f54-e35d-21b692215f02"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyZDQJKUR8k1",
        "outputId": "f72d9962-ff78-4a68-8d44-cbf364c2b885"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 6], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdlU9FrVR_CF",
        "outputId": "99262a83-6cda-4a38-b269-652340a3c8d7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "uP2AyhIWTu8W"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "m7aVIyRRWopP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJkoOCmSUd5-",
        "outputId": "0a5f9469-0abe-42fc-d1db-5d9bf94ab66a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 89)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(len(tokenizer.word_index)+1,100,input_length=max_len-1),\n",
        "    keras.layers.LSTM(100),\n",
        "    keras.layers.Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "7UTmcn2kVbff"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "L2dT7ouYW9qf"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBDEfT3YXKkD",
        "outputId": "4ff3f2cc-9e7e-4043-8d12-f54b5823591b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 30, 100)           8900      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 89)                8989      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98289 (383.94 KB)\n",
            "Trainable params: 98289 (383.94 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjkgfYIpXRFs",
        "outputId": "83e3f8e6-b06a-4eaf-e129-201b11cb2d05"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.0266 - accuracy: 0.4623\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9892 - accuracy: 0.5189\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9512 - accuracy: 0.5566\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.9177 - accuracy: 0.5377\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.8839 - accuracy: 0.6038\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.8441 - accuracy: 0.6415\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.8166 - accuracy: 0.6415\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.7781 - accuracy: 0.6321\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.7564 - accuracy: 0.6132\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.7197 - accuracy: 0.6132\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.6892 - accuracy: 0.6509\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.6555 - accuracy: 0.6321\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.6221 - accuracy: 0.6604\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.6011 - accuracy: 0.6604\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.5691 - accuracy: 0.6887\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.5403 - accuracy: 0.6981\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.5090 - accuracy: 0.7170\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.4831 - accuracy: 0.7642\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.4571 - accuracy: 0.8019\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.4211 - accuracy: 0.8113\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3980 - accuracy: 0.8113\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3785 - accuracy: 0.7736\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3515 - accuracy: 0.8208\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.3284 - accuracy: 0.8491\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3151 - accuracy: 0.8868\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.2800 - accuracy: 0.8774\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.2560 - accuracy: 0.8585\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.2338 - accuracy: 0.9151\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1.1980 - accuracy: 0.9340\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.1680 - accuracy: 0.9340\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.1557 - accuracy: 0.9340\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.1281 - accuracy: 0.9528\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.1041 - accuracy: 0.9434\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.0821 - accuracy: 0.9528\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.0676 - accuracy: 0.9151\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.0427 - accuracy: 0.9434\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.0149 - accuracy: 0.9528\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.9960 - accuracy: 0.9623\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.9782 - accuracy: 0.9340\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.9596 - accuracy: 0.9528\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.9365 - accuracy: 0.9434\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.9135 - accuracy: 0.9434\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.8942 - accuracy: 0.9528\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.8751 - accuracy: 0.9717\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.8616 - accuracy: 0.9717\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.8342 - accuracy: 0.9811\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.8304 - accuracy: 0.9717\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.8256 - accuracy: 0.9717\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.8084 - accuracy: 0.9717\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7841 - accuracy: 0.9717\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7754 - accuracy: 0.9623\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.7558 - accuracy: 0.9623\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.7328 - accuracy: 0.9623\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7225 - accuracy: 0.9623\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7139 - accuracy: 0.9434\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6874 - accuracy: 0.9717\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6721 - accuracy: 0.9623\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6596 - accuracy: 0.9623\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6455 - accuracy: 0.9623\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6319 - accuracy: 0.9717\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6198 - accuracy: 0.9717\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6028 - accuracy: 0.9717\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5933 - accuracy: 0.9717\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5869 - accuracy: 0.9717\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5736 - accuracy: 0.9717\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5627 - accuracy: 0.9717\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5511 - accuracy: 0.9717\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5437 - accuracy: 0.9717\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5330 - accuracy: 0.9717\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.5218 - accuracy: 0.9717\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5109 - accuracy: 0.9623\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5007 - accuracy: 0.9717\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4889 - accuracy: 0.9623\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4776 - accuracy: 0.9717\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4711 - accuracy: 0.9623\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4646 - accuracy: 0.9717\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4575 - accuracy: 0.9623\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.4446 - accuracy: 0.9717\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4384 - accuracy: 0.9717\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4326 - accuracy: 0.9717\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4216 - accuracy: 0.9717\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4223 - accuracy: 0.9717\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4056 - accuracy: 0.9717\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3990 - accuracy: 0.9717\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3963 - accuracy: 0.9717\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3850 - accuracy: 0.9717\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3816 - accuracy: 0.9717\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3753 - accuracy: 0.9717\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3655 - accuracy: 0.9623\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3627 - accuracy: 0.9623\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3529 - accuracy: 0.9717\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3439 - accuracy: 0.9717\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3430 - accuracy: 0.9717\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3357 - accuracy: 0.9623\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3352 - accuracy: 0.9717\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3244 - accuracy: 0.9717\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.3204 - accuracy: 0.9717\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3156 - accuracy: 0.9717\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3075 - accuracy: 0.9717\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3096 - accuracy: 0.9623\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f60e4b3ebf0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'humans are great not apes'\n",
        "\n",
        "for i in range(10):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_token_text = pad_sequences([token_text],maxlen=max_len-1,padding='pre')\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "      print(word)\n",
        "      text = text + \" \" + word\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv-f2mKdZ5dp",
        "outputId": "ae78829a-a45e-4bed-d5b0-caa102151b22"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "to\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "the\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "great\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "apes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "orangutans\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "orangutans\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "are\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "distinguished\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "by\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "a\n",
            "humans are great not apes to the great apes orangutans orangutans are distinguished by a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(padded_token_text).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE3BJM1paaVg",
        "outputId": "9c96ec38-a4f4-4e1b-a4df-49dda2007cea"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 89)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "2bnyAYXjap0f"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et4qiSmIay0t",
        "outputId": "46860f99-8d43-463e-9f25-9f4ea0f4e5c3"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79vrFUZIbI5X",
        "outputId": "cc3ecbbe-3ab4-48ce-9ed2-10e941a7ca28"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "humans\n"
          ]
        }
      ]
    }
  ]
}